---
title: "Dealing with spatial data"
author:
- Gema Fernández-Avilés, UCLM
- Diego Hernangómez
date: "`r Sys.Date()`"
bibliography: dealing.bib
csl: apa-6th-edition.csl
editor_options:
  markdown:
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE
)


hlp_install <- function(pkg) {
  if (isFALSE(requireNamespace(pkg, quietly = TRUE))) {
    install.packages(pkg)
  }
}


hlp_install("devtools")

devtools::install_cran(c(
  "mapSpain", "raster", "sf", "gstat", "sp",
  "dplyr", "ggplot2", "geoR", "classInt"
))
```

**Gema**

-   [ ] Revisa referencias bibliográficas
-   [ ] Me cuesta encajar la sección de Exploratory Spatial Data Analysis.

## 0. What is spatial data?

Geospatial data is any data that contain information about a specific location
on the Earth's surface. Spatial data arise in a myriad of fields and
applications, so there is also a myriad of spatial data types. @cressie93
provides a simple and useful classification of spatial data:

1.  **Geostatistical data** (air temperature values in a country),
2.  **Lattice data** (unemployment rate by states),
3.  **Point patterns** (the location of fires in a region).

See @montero_spatial, for more details.

In this work,we focus on geostatistical data.

### What we need to run geostatistical data in R?

Some useful libraries we are going to use on this article:

```{r libraries}
library(climaemet) # meteorological data
library(mapSpain) # base maps of Spain

library(classInt) # classification

library(raster) # raster handling
library(sf) # spatial shape handling
library(sp) # spatial shape handling
library(gstat) # for spatial interpolation
library(geoR) # for spatial analysis

library(dplyr) # data handling
library(ggplot2) # for plots
```

### Where can we find geostatistical data?

In this paper, we are going to deal with geostatistical data, specifically we
are going to model the level of air temperature in Spain on **12 August 2021**.

We are going to download the data with **climaemet** package in R. **climaemet**
allows to download the climatic data of the Spanish Meteorological Agency
(AEMET) directly using their API. On this article we would use **climaemet
(\>=1.0.0)** (version not released on CRAN yet at the time of writing this
article), so it is needed to install the developing version.

You can install the developing version of **climaemet** using the
[r-universe](https://ropenspain.r-universe.dev/ui#builds):

```{r runiverse, eval=FALSE}
# Enable this universe
options(repos = c(
  ropenspain = "https://ropenspain.r-universe.dev",
  CRAN = "https://cloud.r-project.org"
))

install.packages("climaemet")
```

Alternatively, you can install the developing version of **climaemet** with:

```{r remotes, eval=FALSE}
library(remotes)
install_github("ropenspain/climaemet")
```

#### API Key

To be able to download data from AEMET you will need also a free API key which
you can get [here](https://opendata.aemet.es/centrodedescargas/obtencionAPIKey).

```{r apikey, eval=FALSE}
library(climaemet)

# Get api key from AEMET
browseURL("https://opendata.aemet.es/centrodedescargas/obtencionAPIKey")

# Use this function to register your API Key temporarly or permanently
aemet_api_key("<MY API KEY>")
```

## 1. How is the structure of geostatistical data?

Geostatistical data arise when the domain under study is a fixed set $D$ that is
continuous. That is: (i) $Z(s)$ can be observed at whichever point of the domain
(continuous); and (ii) the points in $D$ are non-stochastic (fixed, $D$ is the
same for all the realizations of the spatial random function).

First, take a look of the characteristics of the stations. We are interesting in
**latitude** and **longitude** attributes.

```{r stations}
stations <- aemet_stations()

# Have a look on the data
stations %>%
  dplyr::select(nombre, latitud, longitud) %>%
  head() %>%
  knitr::kable()
```

Now we can start extracting the data. We select here the daily values on **12
August 2021**:

```{r selectdaily}
# Select data

date_select <- "2021-08-12"


clim_data <- aemet_daily_clim(
  start = date_select,
  end = date_select,
  return_sf = TRUE
)
```

We can examine the possible variables that can be analyzed. We are interested in
**maximum daily temperature** named `tmax`, although the API provides also other
interesting information:

```{r namesdaily}
names(clim_data)
```

On this step, we select the variable of interest on each station. For simplicity
we would focus on mainland Spain only:

```{r selecttemp, fig.cap="Figure 1: AEMET Stations, mainland Spain"}
clim_data_clean <- clim_data %>%
  # Exclude Islands from analysis
  filter(!provincia %in% c(
    "LAS PALMAS", "STA. CRUZ DE TENERIFE",
    "ILLES BALEARS"
  )) %>%
  dplyr::select(fecha, tmax) %>%
  # Exclude NAs
  filter(!is.na(tmax))


# Plot with outline of Spain

CCAA <- esp_get_ccaa(epsg = 4326) %>%
  # Exclude Canary Islands from analysis
  filter(!ine.ccaa.name %in% c("Canarias", "Balears, Illes"))

ggplot(CCAA) +
  geom_sf() +
  geom_sf(data = clim_data_clean) +
  theme_light()
```

Let's plot now the values as a choropleth map:

```{r choro, fig.cap="Figure 2: Spain - Max. temperature 12 Aug. 2021"}

# This would be common to all the paper
br_paper <- seq(15, 45, 5)
pal_paper <- hcl.colors(15, "PuOr", rev = TRUE)

ggplot(clim_data_clean) +
  geom_sf(data = CCAA, fill = "grey95") +
  geom_sf(aes(fill = tmax),
    shape = 21,
    size = 6,
    alpha = .7
  ) +
  labs(fill = "Max. temp") +
  scale_fill_gradientn(
    colours = pal_paper,
    breaks = br_paper,
    labels = function(x) {
      paste0(x, "º")
    },
    guide = "legend"
  ) +
  theme_light()
```

## 2. Are independent the observations or they exhibit spatial dependence?

Everything is related to everything else. But near things are more related than
distant things [@tobler69].

In our study, we can observe positive spatial dependence (see Figure 2), high
values of temperature are all together in the south of Spain and low
temperatures are also together in the north of Spain.

```{r summ}

clim_data_clean %>%
  st_drop_geometry() %>%
  select(tmax) %>%
  summarise_all(
    funs(min, max, median, sd,
      n = n(),
      q25 = quantile(., .25),
      q75 = quantile(., .75)
    )
  ) %>%
  knitr::kable()
```

On the next plot we divide the maximum temperature into quartiles to visualize
the spatial distribution of values:

```{r bubbleplot, fig.cap="Figure 3: Spain - Max. temperature 12 Aug. 2021 - Quartiles" }
bubble <- clim_data_clean %>% arrange(desc(tmax))

# Create quartiles
cuart <- classIntervals(bubble$tmax, n = 4)
bubble$quart <- cut(bubble$tmax, breaks = cuart$brks, labels = FALSE)

ggplot(bubble) +
  geom_sf(
    aes(size = quart, fill = quart),
    col = "grey20",
    alpha = 0.7,
    shape = 21
  ) +
  scale_size(
    range = c(2, 8),
    labels = function(x) paste0("Q", x),
    guide = guide_legend()
  ) +
  scale_fill_gradientn(
    colours = pal_paper,
    labels = function(x) paste0("Q", x)
  ) +
  guides(fill = guide_legend(title = "")) +
  labs(
    size = ""
  ) +
  theme_light()
```

## 3. Prepare the data as spatial object

**An important thing to consider in any spatial analysis or visualization** is
the [coordinate reference system
(CRS)](https://en.wikipedia.org/wiki/Spatial_reference_system). On this
exercise, we choose to project our objects to ETRS89 / UTM zone 30N
[EPSG:25830](https://epsg.io/25830), that provides projected x and y values on
meters and maximizes the accuracy for Spain.

```{r transform}
clim_data_utm <- st_transform(clim_data_clean, 25830)

CCAA_utm <- st_transform(CCAA, 25830)
```

### Create a grid for the spatial prediction

As we need to predict values at locations where no measurements have been made,
we need to create a grid of locations and perform an interpolation.

This grid is composed to equally spaced points over the whole extent (bounding
box) of Spain. Most of the squares does not have any station, hence no
observation is available. However, we would use the values of the cells that
encloses any station for interpolating the data.

```{r create_grid}

# Create grid 5*5 km (25 km2)

grd_sf <- st_as_sfc(st_bbox(CCAA_utm)) %>%
  st_make_grid(
    cellsize = 5000,
    what = "centers"
  )

# Convert to sp object - interpolation should be made with sp/raster
grd <- as(grd_sf, "Spatial") %>%
  as("SpatialPixels")
```

There are some additional steps we must perform in order to prepare our data for
spatial interpolation. We ensure

```{r remove_dups}
# Prepare the data. Change to sp for this analysis
clim_data_clean_sp <- as(clim_data_utm, "Spatial")

# Remove duplicate locations
zd <- zerodist(clim_data_clean_sp)

# Remove the duplicate rows and back to sf
clim_data_clean_nodup_sp <- clim_data_clean_sp[-zd[, 2], ]
clim_data_clean_nodup <- clim_data_clean_nodup_sp %>%
  st_as_sf()
```

## 4. Exploratory Spatial Data Analysis

Look the histogram, the dataset is gaussian!! Note that kriging is
[BLUP](https://en.wikipedia.org/wiki/Best_linear_unbiased_prediction).

```{r hist, fig.cap="Figure 4: Spain - Max. temperature 12 Aug. 2021 - Histogram"}

ggplot(clim_data_clean_nodup, aes(x = tmax)) +
  geom_histogram(aes(fill = cut(tmax, 15)),
    binwidth = 1,
    show.legend = FALSE
  ) +
  scale_fill_manual(values = pal_paper) +
  labs(
    y = "n obs.",
    x = "Max. temp (º)"
  ) +
  theme_light()
```

DIEGO: QUITARÍAMOS IDW O LO DEJAMOS PARA COMPARAR...?
GEMA: LO QUITO DE MOMENTO

## 5. Kriging Ordinary

GEMA, AQUI YO PONDRIA MAS CHICHA...

### Prepare the geospatial object with **geoR** package

```{r krig_prepare, fig.cap="Figure 5: Ordinary Kriging"}
library(geoR)

mydata.geo <- clim_data_clean_nodup %>%
  st_coordinates() %>%
  as.data.frame() %>%
  mutate(
    lon = X,
    lat = Y
  ) %>%
  select(-X, -Y) %>%
  bind_cols(tmax = clim_data_clean_nodup$tmax)

mydata <- as.geodata(obj = mydata.geo, coords.col = 1:2, data.col = 3)
```

The semivariogram function requiere a more depth study. Now, we show two
different functions to fit the empirical semivariogram to a theoretical
semivariogram.

GEMA, CAMBIÉ El DIA, PUEDES REVISAR LOS PARAMETROS? NO ME SALE...

```{r variog}
# geoR::variog()
vario.b <- variog(mydata, coords = mydata$coords, data = mydata$data)
plot(vario.b)

# eyefit() is an interactive function to play with the types and parameters of semivariogram.

# eyefit(vario.b)
#  cov.model sigmasq       phi tausq kappa kappa2 practicalRange
# spherical   29.26 766374.98  0.98  <NA>   <NA>      766374.98


# Fit the semivariogram by eye in gstat()
vgm <- variogram(tmax ~ 1, clim_data_clean_nodup_sp)
plot(vgm)

fit.var <- fit.variogram(vgm, model = vgm(0, "Sph", 766374.98, 29.26))

# Plot empirical (dots) and theoretical semivariograms (line)
plot(vgm, fit.var, col = 2)
```

## 6. Compute ordinary kriging and plot the results

There are different kinds of kriging depend on the characteristics of the
spatial process: simple, ordinary or universal kriging (external drift kriging),
kriging in a local neighbourhood, point kriging or kriging of block mean values
and conditional (Gaussian or indicator) simulation equivalents for all kriging
varieties.

In this work we deal with ordinary kriging, the most widely used kriging method.
It serves to estimate a value at a point of a region for which a variogram is
known, using data in the neighborhood of the estimation location.

```{r krig_res, fig.cap="Figure 6: Ordinary Kriging - Results"}
kriged <- krige(tmax ~ 1, clim_data_clean_nodup_sp, grd, model = fit.var)

spplot(kriged["var1.pred"], main = "Ordinary kriging predictions")
spplot(kriged["var1.var"], main = "Ordinary kriging variance")
```

## ----------- HASTA AQUÍ TODO BIEN ----------------

```{r, eval=FALSE}

# Mapas mas bonitos
# DHH Creamos un mapa con ggplot2

idw_df <- as.data.frame(interp_temp, xy = TRUE, na.rm = TRUE)

# Cortes para hacer choropleth
library(classInt)
breaks_idw <- classIntervals(idw_df$var1.pred, style = "pretty", n = 7)



ggplot() +
  geom_tile(data = idw_df, aes(x = coords.x1, y = coords.x2, fill = var1.pred)) +
  geom_sf(data = CCAA_utm, col = "black", fill = NA) +
  scale_fill_gradientn(
    limits = c(-10, 18),
    colours = hcl.colors(11, "RdBu", rev = TRUE, alpha = 0.7),
    breaks = breaks_idw$brks,
    labels = function(x) {
      paste0(x, "º")
    },
    guide = guide_legend(reverse = TRUE, title = "Ave. of Spain Temperature")
  ) +
  theme(
    panel.background = element_blank(),
    axis.title = element_blank()
  ) +
  labs(
    title = "Ave. of Spain Temperature",
    subtitle = "Inverse Distance Weighted Interpolation",
    caption = "Data: AEMET, IGN"
  )

# para krigged
kriged_df <- as.data.frame(kriged, xy = TRUE, na.rm = TRUE)

# OJO, reutilizo breaks idw para hacerlo comparable
ggplot() +
  geom_tile(data = kriged_df, aes(x = coords.x1, y = coords.x2, fill = var1.pred)) +
  geom_sf(data = CCAA_utm, col = "black", fill = NA) +
  scale_fill_gradientn(
    limits = c(-10, 18),
    colours = hcl.colors(11, "RdBu", rev = TRUE, alpha = 0.7),
    breaks = breaks_idw$brks,
    labels = function(x) {
      paste0(x, "º")
    },
    guide = guide_legend(reverse = TRUE, title = "Temperature")
  ) +
  theme(
    panel.background = element_blank(),
    axis.title = element_blank()
  ) +
  labs(
    title = "Ave. of Spain Temperature",
    subtitle = "Kriging interpolation",
    caption = "Data: AEMET, IGN"
  )

ggplot() +
  geom_tile(data = kriged_df, aes(x = coords.x1, y = coords.x2, fill = var1.var)) +
  geom_sf(data = CCAA_utm, col = "black", fill = NA) +
  geom_sf(data = test_day_sf2, col = "black", pch = 3) +
  scale_fill_gradientn(
    # Creamos una paleta especial
    colours = c("green4", "white", hcl.colors(20, "Reds", alpha = .7, rev = TRUE)),
    breaks = c(0, 3, 4, 5, 10, 20, 30),
    guide = guide_legend(reverse = TRUE, title = "Varianza")
  ) +
  theme(
    panel.background = element_blank(),
    axis.title = element_blank(),
    plot.tag.position = c(.8, .2),
    plot.tag = element_text(hjust = -.3, size = 9)
  ) +
  labs(
    title = "Ave. of Spain Temperature",
    subtitle = "Kriging variance",
    caption = "Data: AEMET, IGN",
    tag = "+ AEMET Monitoring Stations "
  )
```

```{r, eval=FALSE}

# Making a nice plot on ggplot2
temp_values <- as.data.frame(interp_temp, xy = TRUE, na.rm = TRUE)
names(temp_values) <- c("x", "y", "temp")

# Get min and max from interpolated values
min_temp <- floor(min(temp_values$temp))
max_temp <- ceiling(max(temp_values$temp))

ggplot() +
  geom_sf(data = CCAA_utm, fill = "grey95") +
  geom_tile(data = temp_values, aes(x = x, y = y, fill = temp)) +
  scale_fill_gradientn(
    colours = hcl.colors(11, "Spectral", rev = TRUE, alpha = 0.7),
    limits = c(min_temp, max_temp)
  ) +
  theme_minimal() +
  ylab(NULL) +
  xlab(NULL) +
  labs(
    title = "Avg. Temperature in Spain",
    subtitle = "2021-01-08",
    caption = "Data: AEMET, IGN",
    fill = "C"
  )
```

## References
